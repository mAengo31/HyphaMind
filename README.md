# HypaMind
HypaMind is a novel hypothesis generation framework that is responsible for generating new ideas from the current corpus. It is the first major building block toward a fully autonomous AI Scientist.

Currently HypaMind is focused on the CS field, however it could easily be extended to other corpuses in the future.


## What HypaMind Does
- Large-Scale Corpus Analysis: Ingests a massive collection of scientific papers and structures them into problem–method representations.
- Conceptual Mapping: Uses advanced language embeddings and clustering to model the conceptual space of research ideas.
- Novelty-Aware Candidate Generation: Applies a two-hop retrieval and cross-domain search strategy to identify method-problem pairs that have potential for novelty and scientific value.
- Hypothesis Formulation: Uses a specialized LLM pipeline to draft high-level hypotheses in a formal, academic tone, citing relevant works for credibility.

## HypaMind pipeline
1. Data retrival: Data is collected via arxiv metadata.
2. Data Preparation: problems and methods are extracted from the datasets and arranged. 
3. Data Encoding: Embeds prepared data into tokens for the machines & constructs a FAISS index.
4. Data Analysis: Clusters dual dataset through leiden clustering.
5. Inspiration Mining: Implements 3 different search methods (direct KNN, two-hop, cluster-bridging) to link a cloud of potentially related methods to existing problems.
6. Hypothesis Generation: Feeds the cloud of problem-method combinations to an LLM to generate an original combination + confirm novelty via DOI search.

### Sample Hypothesis generated by HypaMind (novelty confirmed)

1) Computer Science - C-GRU model

Hypothesis: 
"A hybrid "Caudate-Gated Recurrent Unit" (C-GRU) model is proposed, integrating the adaptive, gated temporal learning of GRUs with a connectivity constraint matrix derived from primate caudate nucleus wiring diagrams." 

Rationale: 
"The C-GRU selectively gates information flow within the recurrent unit based on the learned caudate connectivity matrix, mimicking the basal ganglia's role in action selection and sequence learning. This biologically-inspired constraint is hypothesized to improve long-range dependency resolution and reduce vanishing gradients in complex sequential tasks, outperforming standard GRU and RNN architectures.  Nahl's model of the basal ganglia-thalamocortical loops further motivates exploring the role of adaptive processes in gating information flow, which is a key component of our proposed hybrid model." 

2) Computer Science - GAN training method

Hypothesis:
"A novel generative adversarial training method is proposed, integrating layer-wise subspace learning with a two-time-scale GDA framework.  This hybrid approach aims to improve training stability and accelerate convergence by aligning the generator and discriminator feature spaces in a hierarchical manner, leveraging the theoretical guarantees of two-time-scale optimization."

Rationale: 
"Two-time-scale Gradient Descent Ascent (GDA) offers theoretical convergence guarantees under specific conditions, addressing the instability often observed in GAN training.  Layer-wise subspace learning, by focusing on aligning feature representations at different granularities, can improve the discriminator's ability to provide informative feedback to the generator, thereby enhancing training efficiency and generated sample quality.  Combining these methods offers a synergistic approach to address the limitations of existing GAN training procedures."

3) Biology - Ligand docking

Hypothesis:
"A novel ligand docking approach hybridizes smoothed potentials with a Lamarckian genetic algorithm (LGA) within the S4MPLE docking tool.  This enhanced S4MPLE tool utilizes smoothed potential energy functions during the LGA's local search phase to refine ligand poses and improve docking accuracy."

Rationale: 
"Smoothed potentials, by reducing energy barriers, can enhance the exploration of conformational space during the local search of the LGA.  This combination is expected to improve docking prediction accuracy compared to traditional scoring functions in S4MPLE, as demonstrated by the superior performance of smoothed potentials in protein folding simulations and the effectiveness of LGAs in exploring complex search spaces (Cormen et al., 2009)."

## Next Steps

HypaMind is Phase 1 of a broader system aimed at:
1.	Hypothesis Generation _(completed MVP)._
2.	Experiment Planning & Code Synthesis: Automatically design experiments and generate runnable code pipelines for evaluation. **(currently in progress)**
3.	Result Integration: Benchmark outcomes, validate ideas, and iterate automatically.
4.	Manuscript Drafting & Submission: Generate publication-ready papers in LaTeX based on validated experiments and human-in-the-loop refinement.

### Tech Stack Highlights
	•	Languages: Python system + Rust backbone
	•	Core Components: FAISS for scalable similarity search, advanced clustering (Leiden), LLM-based hypothesis generator (cloud + local inference).

